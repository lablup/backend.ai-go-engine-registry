{
  "schemaVersion": 1,
  "lastUpdated": "2026-01-10T15:25:09Z",
  "baseUrl": "https://github.com/lablup/backend.ai-go-engine-registry/releases/download",
  "engines": [
    {
      "id": "llama-cpp",
      "name": "llama.cpp",
      "description": "High-performance GGUF model inference engine",
      "supportedFormats": [
        "gguf"
      ],
      "platforms": [
        "darwin",
        "linux",
        "win32"
      ],
      "latest": {
        "version": "0.0.1",
        "releaseDate": "2026-01-10",
        "minAppVersion": "0.8.0",
        "packages": [
          {
            "os": "darwin",
            "arch": "arm64",
            "accelerator": "metal",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-darwin-arm64-metal.baiengine",
            "size": 11738818,
            "sha256": "50be5d2f77f220093c7b3c05696209621494bb93fe5dface7f9d58c3a887bf44"
          },
          {
            "os": "linux",
            "arch": "x64",
            "accelerator": "cpu",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-linux-x64-cpu.baiengine",
            "size": 13599090,
            "sha256": "370c921e83b62433dae56200c4016e3b27cfca7fb8bd051e741dec92d4f08c57"
          },
          {
            "os": "linux",
            "arch": "x64",
            "accelerator": "vulkan",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-linux-x64-vulkan.baiengine",
            "size": 30100473,
            "sha256": "0761b95d7b533f0eb7158953a008b42ddaa6dc3d7fdb5a2165a2581c297fb421"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "cpu",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-win32-x64-cpu.baiengine",
            "size": 15514936,
            "sha256": "b586a4a270e4b19054dd49ca72d208fee4b041289c5a62f87cbad2d1b6d64f52"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "cuda12",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-win32-x64-cuda12.baiengine",
            "size": 205717999,
            "sha256": "53cb6901f1ca4e30487b27575f29509455dcef89fb58555a56dc5c50ccdc8872"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "cuda13",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-win32-x64-cuda13.baiengine",
            "size": 127881563,
            "sha256": "07752ed7964d94ee7d7425c274e1b57d79f1adcaeba4164f4c5535085105751e"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "hip",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-win32-x64-hip.baiengine",
            "size": 126330527,
            "sha256": "3e88a321d4446fc0e03d7e4cc21d8b1b71fedfcd20eefd275f729676a7498c7a"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "sycl",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-win32-x64-sycl.baiengine",
            "size": 105831734,
            "sha256": "520cce247a328608473d533eb510a8f9bcd84f250fc3ad4e26b771a1dc928015"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "vulkan",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.1-win32-x64-vulkan.baiengine",
            "size": 31781212,
            "sha256": "2974e58547a8b3b6239dba68fa5cf8b8fc080d00b0a08f0fa54f13097467f6fd"
          }
        ]
      }
    }
  ],
  "runtimes": []
}

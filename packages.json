{
  "schemaVersion": 1,
  "lastUpdated": "2026-01-11T04:12:41Z",
  "baseUrl": "https://github.com/lablup/backend.ai-go-engine-registry/releases/download",
  "engines": [
    {
      "id": "llama-cpp",
      "name": "llama.cpp",
      "description": "High-performance GGUF model inference engine",
      "supportedFormats": [
        "gguf"
      ],
      "platforms": [
        "darwin",
        "linux",
        "win32"
      ],
      "latest": {
        "version": "0.0.2",
        "releaseDate": "2026-01-11",
        "minAppVersion": "0.8.0",
        "packages": [
          {
            "os": "darwin",
            "arch": "arm64",
            "accelerator": "metal",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-darwin-arm64-metal.baiengine",
            "size": 11769081,
            "sha256": "2a62418521288f2fbc8eff65f7d49fea437d880c099e899e3ca4dea00f3b4b0c"
          },
          {
            "os": "linux",
            "arch": "x64",
            "accelerator": "cpu",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-linux-x64-cpu.baiengine",
            "size": 13618324,
            "sha256": "0fe3c57ab30ef87197019f5bd3c9ad45af6502ad1dff5a2cd77ab7b0b0bc0c48"
          },
          {
            "os": "linux",
            "arch": "x64",
            "accelerator": "vulkan",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-linux-x64-vulkan.baiengine",
            "size": 30119704,
            "sha256": "fdf76104b766288ac576e0a0fb6b935dec1a6e6832ee49baf6060203d0be07dd"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "cpu",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-win32-x64-cpu.baiengine",
            "size": 15529194,
            "sha256": "4ce55904a1faa45e4c5db187b851176cb8d6d1a05855ea067c75e44f9b52e684"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "cuda12",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-win32-x64-cuda12.baiengine",
            "size": 205731724,
            "sha256": "21c24736f44fc65a9357ae90041e7e1d771608506ec9f59e53f1ac47ee95b32c"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "cuda13",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-win32-x64-cuda13.baiengine",
            "size": 127895428,
            "sha256": "e4de3791e095681a0b49d2b6f86f7df551f70cc6b9e56f78261f2a6acc92da52"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "hip",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-win32-x64-hip.baiengine",
            "size": 99630206,
            "sha256": "5003fe0e534060abe525955a6b1a92215e3b3612fc6068d40b7c268614144353"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "sycl",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-win32-x64-sycl.baiengine",
            "size": 105845993,
            "sha256": "67ddc84a0c495ab15692166dc0a5393f4cd7b8b608f5b4e2596371d8f5d80f9f"
          },
          {
            "os": "win32",
            "arch": "x64",
            "accelerator": "vulkan",
            "acceleratorVersion": null,
            "filename": "llama-cpp-0.0.2-win32-x64-vulkan.baiengine",
            "size": 31795471,
            "sha256": "d2c94370f05db6ab3b3ea3c3ce51cde01a8ced739e2e39896fcc5eabca611f76"
          }
        ]
      }
    }
  ],
  "runtimes": [
    {
      "id": "hip-runtime",
      "name": "HIP Runtime for Windows",
      "description": "AMD HIP runtime libraries and GPU kernels for Windows (rocblas, hipblaslt)",
      "category": "rocm",
      "platforms": [
        "win32"
      ],
      "latest": {
        "version": "6.2.0",
        "releaseDate": "2026-01-11",
        "packages": [
          {
            "os": "win32",
            "arch": "x64",
            "filename": "hip-runtime-6.2.0-win32-x64.bairuntime",
            "size": 247976963,
            "sha256": "2cc39cecaf12e4e8ff4bd7aad1dc60d2704d9d8af24cac4461d15f5e62397bd4"
          }
        ]
      }
    },
    {
      "id": "cuda12-runtime",
      "name": "CUDA 12 Runtime",
      "description": "NVIDIA CUDA 12 runtime libraries (cuBLAS, cuBLASLt, cuDNN)",
      "category": "cuda",
      "platforms": [
        "win32"
      ],
      "latest": {
        "version": "12.4.0",
        "releaseDate": "2026-01-11",
        "packages": [
          {
            "os": "win32",
            "arch": "x64",
            "filename": "cuda12-runtime-12.4.0-win32-x64.bairuntime",
            "size": 396574964,
            "sha256": "a1a1a808bc59be81da7939f4acd8ebec27c0deafb7aaab1ec987149563a6c6a9"
          }
        ]
      }
    },
    {
      "id": "cuda13-runtime",
      "name": "CUDA 13 Runtime",
      "description": "NVIDIA CUDA 13 runtime libraries (cuBLAS, cuBLASLt, cuDNN)",
      "category": "cuda",
      "platforms": [
        "win32"
      ],
      "latest": {
        "version": "0.0.2",
        "releaseDate": "2026-01-11",
        "packages": [
          {
            "os": "win32",
            "arch": "x64",
            "filename": "cuda13-runtime-13.1.0-win32-x64.bairuntime",
            "size": 403008211,
            "sha256": "c399262e0cc00f2e6830dd1956803c15f6c13b346c7d1690f2c0b244b81e4b1f"
          }
        ]
      }
    }
  ]
}
